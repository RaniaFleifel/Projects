{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP requests code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APIkey: 4nPd9w1xNUFWvYaQzjhLrX8FoPAFqMkb\n",
    "\n",
    "import datetime\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "KEY = \"4nPd9w1xNUFWvYaQzjhLrX8FoPAFqMkb\"\n",
    "date = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "BASE_REQUEST = (\n",
    "        \"https://api.nytimes.com/svc/search/v2/articlesearch.json\"\n",
    ")\n",
    "\n",
    "payload = {\n",
    "  \"api-key\": KEY,\n",
    "  \"begin_date\": date,\n",
    "  \"end_date\": date,\n",
    "  \"q\": \"Donald Trump\"\n",
    "}\n",
    "\n",
    "r = requests.get(BASE_REQUEST, params=payload)\n",
    "\n",
    "if r.status_code == 200:\n",
    "    print(r.json())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML - soup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "r = requests.get('https://en.wikipedia.org/wiki/Web_scraping')\n",
    "\n",
    "if r.status_code == 200:\n",
    "    print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#!pip install bs4 \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "r = requests.get('https://en.wikipedia.org/wiki/Web_scraping')\n",
    "\n",
    "if r.status_code == 200:\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    \n",
    "    for headline in soup.find_all(\"span\", {\"class\": \"mw-headline\"}):\n",
    "        print(headline.text)\n",
    "        \n",
    "        spotligt-tab: <a class=\"nav-link filters__tab-link js-tab-link active\" id=\"spotlight-tab\" data-toggle=\"tab\" href=\"#spotlight-panel\" role=\"tab\" aria-controls=\"spotlight-panel\" aria-selected=\"true\">Spotlights</a>\n",
    "        company name: <h2 class=\"ink__title\" data-size=\"lg\" data-font-family=\"unica\" data-word-wrap=\"true\" data-font-size=\"lg\">DoorDash</h2>\n",
    "        company url: <a class=\"ink\" href=\"https://www.sequoiacap.com/companies/doordash/\" style=\"background-color: #00a071\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP requests full example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import bs4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def delay() -> None:\n",
    "    time.sleep(random.uniform(15, 30))\n",
    "    return None\n",
    "\n",
    "\n",
    "base_url = \"https://www.sequoiacap.com/companies/\"\n",
    "content: dict = {\n",
    "    \"name\": [],\n",
    "    \"summary\": [],\n",
    "    \"url\": [],\n",
    "    \"socialmedia\": [],\n",
    "    \"description\": [],\n",
    "    \"milestones\": [],\n",
    "    \"team\": [],\n",
    "    \"partners\": []\n",
    "}\n",
    "\n",
    "delay()\n",
    "r=requests.get(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if r.status_code == 200:\n",
    "    soup= BeautifulSoup(r.content, \"html.parser\")\n",
    "    titles=soup.find_all(\"h2\", {\"class\": \"ink__title\"})\n",
    "    details=soup.find_all(\"div\", {\"class\": \"ink__detail\"})\n",
    "    \n",
    "    for i in range(len(titles)):\n",
    "        print(i, 'out of',len(titles))\n",
    "\n",
    "        socialmedia=[]\n",
    "        milestones=[]\n",
    "        team=[]\n",
    "        partner=[]\n",
    "        print(\"############################################################ \\nname:\",titles[i].text)\n",
    "        print(\"summary:\",details[i].text)\n",
    "        full_url=\"https://www.sequoiacap.com/companies/\"+titles[i].text+\"/\"\n",
    "        \n",
    "        rnew = requests.get(full_url)\n",
    "        detailed_soup = BeautifulSoup(rnew.content, \"html.parser\")        \n",
    "        url = detailed_soup.find(\"a\", {\"class\": \"button button--outline-light button--small\"})[\"href\"]\n",
    "        print(\"url:\",url)\n",
    "        all_socialmedia=detailed_soup.find(\"section\", {\"class\": \"social-sharing__options u-mt-0\"}).find_all(\"a\")#.get(\"href\")\n",
    "        \n",
    "        for ii in range(len(all_socialmedia)):\n",
    "            socialmedia.append(all_socialmedia[ii][\"href\"])\n",
    "        print(\"socialmedia:\",socialmedia)\n",
    "        description=detailed_soup.find(\"div\", {\"class\":\"wysiwyg wysiwyg--fs-lg\"}).text.strip()\n",
    "        print(\"description:\",description)\n",
    "        \n",
    "        which_list=detailed_soup.find_all(\"div\",{\"class\":\"clist\"})\n",
    "        \n",
    "        for ii in range(len(which_list)):\n",
    "            title=which_list[ii].find(\"h2\",{\"class\":\"clist__title\"}).text.strip()\n",
    "            \n",
    "            if title==\"Milestones\":\n",
    "                all_milestones=which_list[ii].find(\"ul\",{\"class\":\"clist__list\"}).find_all(\"li\", {\"class\":\"clist__item\"})\n",
    "                for iii in range(len(all_milestones)):\n",
    "                    stripped_milestones = re.sub(r\"[\\n\\t\\s]*\", \"\", all_milestones[iii].text)\n",
    "                    milestones.append(stripped_milestones)\n",
    "                print(\"milestones:\",milestones)\n",
    "        \n",
    "            elif title==\"Team\":\n",
    "                all_team=which_list[ii].find(\"ul\",{\"class\":\"clist__list\"}).find_all(\"li\", {\"class\":\"clist__item\"})\n",
    "\n",
    "                for iii in range(len(all_team)):\n",
    "                    try:\n",
    "                        stripped_teams = all_team[iii].find(\"a\")[\"href\"]\n",
    "                    except:\n",
    "                        stripped_teams = re.sub(r\"[\\n\\t\\s]*\", \"\", all_team[iii].text)\n",
    "                    team.append(stripped_teams)\n",
    "                print(\"team\",team)\n",
    "\n",
    "            elif (title==\"Partner\" or title==\"Partners\"):\n",
    "                all_partners=which_list[ii].find(\"ul\",{\"class\":\"clist__list\"}).find_all(\"li\", {\"class\":\"clist__item\"})\n",
    "\n",
    "                for iii in range(len(all_partners)):\n",
    "                    stripped_partners = all_partners[iii].find(\"a\")[\"href\"]\n",
    "                    partner.append(stripped_partners)\n",
    "                print(\"partner:\",partner)\n",
    "            \n",
    "       #     else:\n",
    "       #         continue\n",
    "                \n",
    "        content[\"name\"].append(titles[i].text)\n",
    "        content[\"summary\"].append(details[i].text)\n",
    "        content[\"url\"].append(url)\n",
    "        content[\"socialmedia\"].append(socialmedia)\n",
    "        content[\"description\"].append(description)\n",
    "        content[\"milestones\"].append(milestones)\n",
    "        content[\"team\"].append(team)\n",
    "        content[\"partners\"].append(partner)\n",
    "        delay()           \n",
    "else:\n",
    "    print(r.status_code)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(content)\n",
    "df = df.replace(\"\", np.nan).fillna(value=\"NA\")\n",
    "df.to_csv(\"webscraping_requests_output.csv\",\n",
    "          index=False,\n",
    "          sep=\";\",\n",
    "          encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_read=pd.read_csv(\"webscraping_requests_output.csv\",sep=';')#.head(5).partner\n",
    "df_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selenium full example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in d:\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Collecting urllib3[socks]~=1.26\n",
      "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in d:\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in d:\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in d:\\anaconda3\\lib\\site-packages (from selenium) (2022.9.24)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.0)\n",
      "Requirement already satisfied: idna in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.8)\n",
      "Requirement already satisfied: async-generator>=1.9 in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.1.0)\n",
      "Requirement already satisfied: cffi>=1.14 in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: outcome in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in d:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (19.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in d:\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in d:\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.19)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in d:\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda3\\lib\\site-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.4.0)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.11\n",
      "    Uninstalling urllib3-1.25.11:\n",
      "      Successfully uninstalled urllib3-1.25.11\n",
      "Successfully installed urllib3-1.26.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda 22.9.0 requires ruamel_yaml_conda>=0.11.14, which is not installed.\n",
      "requests 2.22.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.12 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: selenium\n",
      "Version: 4.5.0\n",
      "Summary: \n",
      "Home-page: https://www.selenium.dev\n",
      "Author: \n",
      "Author-email: \n",
      "License: Apache 2.0\n",
      "Location: d:\\anaconda3\\lib\\site-packages\n",
      "Requires: certifi, trio, trio-websocket, urllib3\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# !conda info\n",
    "import sys\n",
    "!{sys.executable} -m pip install selenium\n",
    "!{sys.executable} -m pip show selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: use options instead of chrome_options\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# configure webdriver\n",
    "options = Options()\n",
    "options.headless = True  # hide GUI\n",
    "options.add_argument(\"--window-size=1920,1080\")  # set window size to native GUI size\n",
    "options.add_argument(\"start-maximized\")  # ensure window is full-screen\n",
    "\n",
    "# configure chrome browser to not load images and javascript\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_experimental_option(\n",
    "    # this will disable image loading\n",
    "    \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    ")\n",
    "\n",
    "browser = webdriver.Chrome(r'D:/chromedriver_win32/chromedriver.exe',options=options, chrome_options=chrome_options)\n",
    "browser.get(\"https://www.twitch.tv/directory/game/Art\")\n",
    "# wait for page to load\n",
    "element = WebDriverWait(driver=browser, timeout=5).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-target=directory-first-item]')))\n",
    "selenium_raw=browser.page_source\n",
    "browser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: parsel in d:\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: w3lib>=1.19.0 in d:\\anaconda3\\lib\\site-packages (from parsel) (2.0.1)\n",
      "Requirement already satisfied: cssselect>=0.9 in d:\\anaconda3\\lib\\site-packages (from parsel) (1.2.0)\n",
      "Requirement already satisfied: lxml in d:\\anaconda3\\lib\\site-packages (from parsel) (4.4.1)\n",
      "Requirement already satisfied: packaging in d:\\anaconda3\\lib\\site-packages (from parsel) (19.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda3\\lib\\site-packages (from packaging->parsel) (2.4.2)\n",
      "Requirement already satisfied: six in d:\\anaconda3\\lib\\site-packages (from packaging->parsel) (1.12.0)\n",
      "[{'title': 'BIRTHDAY MARATHON! Begins Oct. 29th at 11:00am ET. !birthdaystream', 'url': '/bobross', 'tags': ['English'], 'viewers': '16'}, {'title': 'Î¶¨ÎÖ∏Ï∞∏Ïπò Í∑∏Î¶ºÎ∞©ÏÜ°', 'url': '/rinotuna', 'tags': ['ÌïúÍµ≠Ïñ¥'], 'viewers': '841'}, {'title': 'ü§ñ Cat mecha ü§ñ | First mecha commission | Sketching a new waifu later!', 'url': '/tofusenshi', 'tags': ['czech', 'artcommission'], 'viewers': '229'}, {'title': 'Working on covers...| !store !links', 'url': '/sozomaika', 'tags': ['English'], 'viewers': '234'}, {'title': '[ Vtuber ITA ] ~ SUBATHON di Compleanno! Day 7 AAAAAAH ! ~ !throne per farmi un regalo di compleanno !', 'url': '/cappuccino_chan', 'tags': ['italiano', 'art', 'illustration'], 'viewers': '64'}, {'title': '‚ú®üé® your daily dose of motivation üë©\\u200düé®‚ú®', 'url': '/vivisartservice', 'tags': ['English', 'art', 'positive'], 'viewers': '93'}, {'title': \"art strimŸ©( ''œâ'' )Ÿà\", 'url': '/ototaaan', 'tags': ['chill', 'Êó•Êú¨Ë™û', 'illustrator'], 'viewers': '32'}, {'title': '„ÇÑ„Åª', 'url': '/kingu_ch', 'tags': ['Comfy', 'English', 'Êó•Êú¨Ë™û'], 'viewers': '59'}, {'title': '[18+] Traditional art thursdays! Trying watercolour (?) | !socials !discord', 'url': '/redbeanporridge', 'tags': ['traditionalArt', 'Productivity'], 'viewers': '95'}, {'title': 'frogs are back and trying their best~ // !shop [mic on]', 'url': '/artbyzvesta', 'tags': ['DigitalArt', 'lgbtqia', 'Cosy'], 'viewers': '126'}, {'title': 're8 dlc recovery room \\U0001fa78 !throw !discord', 'url': '/cirilla_vt', 'tags': ['Chill', 'Vampire', 'VTuber'], 'viewers': '138'}, {'title': 'Sculpting Gabriel Angelos / Dawn of War 3 / Day 30', 'url': '/cnotbusch', 'tags': ['Familyfriendly', 'sculpture'], 'viewers': '141'}, {'title': 'Only 30 hours more! type !kickstarter to check out the goods!! Preparing for the closing day.', 'url': '/nisego', 'tags': ['Drawing', 'Nisego', 'English'], 'viewers': '95'}, {'title': '¬¨ LAST FOUR !streamink ¬¨ !kofi ¬¨ !huel', 'url': '/sezza', 'tags': ['drawing', 'draw', 'artcommissions'], 'viewers': '102'}, {'title': '3D Vtuber Waifus üíºShirahiko Day 16üíº', 'url': '/shonzo', 'tags': ['3DModeling', 'English', 'Anime'], 'viewers': '142'}, {'title': \"Cyno's grippers be looking tasty\", 'url': '/homodacchi', 'tags': ['LGBTQIAplus', 'Asian', 'English'], 'viewers': '43'}, {'title': 'DOODLES TO END STREAM', 'url': '/paperbag_ch', 'tags': ['SplashWomanThePresequel'], 'viewers': '34'}, {'title': \"We're building a Corner Store in 3D! C4D + Octane, EN!\", 'url': '/planetzomax', 'tags': ['octane', 'CGI', 'zomax'], 'viewers': '58'}, {'title': '„Å°„Çá„Å£„Å®ÁµµÊèè„ÅÑ„Åü„Çä„Åó„Çà„ÅÜ„Åã„Å™', 'url': '/viva_h', 'tags': ['illustration', 'Êº´Áîª'], 'viewers': '170'}, {'title': 'Umbreon I choose you! chat, watch or lurk!', 'url': '/sariaarts', 'tags': ['English', 'British', 'Cooperative'], 'viewers': '30'}, {'title': 'will i ever finish this', 'url': '/jasjaws', 'tags': ['English'], 'viewers': '16'}, {'title': 'keep working and no dying pls ‚ú¶ !commissions !tools !who', 'url': '/lunacyhilly', 'tags': ['ArtCommissions', 'VTuber'], 'viewers': '51'}, {'title': '[Vartist] smol paper dgjashgdhasjhd !commission !queue', 'url': '/papertalisman', 'tags': ['Live2d', 'Drawing', 'English'], 'viewers': '19'}, {'title': 'Live2d Rigging ; Games later', 'url': '/rotuslotus', 'tags': ['Live2D', 'English'], 'viewers': '47'}, {'title': \"Squaktober streaaam!!! looking at everyone's beautiful SQUAKS // birding of course\", 'url': '/ipaintbirbs', 'tags': ['giddyup', 'dingus', 'chill'], 'viewers': '148'}, {'title': 'Designing dnd chars day !', 'url': '/muchinery', 'tags': ['artcommissions', 'asexual'], 'viewers': '78'}, {'title': '[EN/JP] Chainsaw Man Collab with Sujipii~ (!collab) || Aki / Himeno || Mic [ON] / SR [OFF]', 'url': '/darkco4', 'tags': ['design', 'original', 'fanart'], 'viewers': '28'}, {'title': '‚≠êÔ∏èArt‚≠êÔ∏è |Screaming [Eng/UK | 18+ | They/Them]', 'url': '/hozzerino', 'tags': ['VTuber', 'UseMeLikeATissue'], 'viewers': '84'}, {'title': \"[ENG/‰∏≠Êñá] ‚ú®Community Art Bun Bun ~ Let's embrace the love‚ú® | !stardust !event !coms !discord\", 'url': '/starlowvince', 'tags': ['Celebration', 'Chatty', 'Malaysia'], 'viewers': '49'}, {'title': ' ö(*¬¥Íí≥`*)…û Huevember Day 3 || !garden !study || only voice', 'url': '/chacuri', 'tags': ['procreate', 'huevember', 'English'], 'viewers': '13'}]\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install parsel\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from parsel import Selector\n",
    "\n",
    "sel = Selector(text=selenium_raw)\n",
    "selenium_content = []\n",
    "for item in sel.xpath(\"//div[contains(@class,'tw-tower')]/div[@data-target]\"):\n",
    "    selenium_content.append({\n",
    "        'title': item.css('h3::text').get(),\n",
    "        'url': item.css('.tw-link::attr(href)').get(),\n",
    "        #'username': item.css('.tw-link::text').get(),\n",
    "        'tags': item.css('.tw-tag ::text').getall(),\n",
    "        'viewers': ''.join(item.css('.tw-media-card-stat::text').re(r'(\\d+)')),\n",
    "    })\n",
    "\n",
    "#print(selenium_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>tags</th>\n",
       "      <th>viewers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIRTHDAY MARATHON! Begins Oct. 29th at 11:00am...</td>\n",
       "      <td>/bobross</td>\n",
       "      <td>['English']</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Î¶¨ÎÖ∏Ï∞∏Ïπò Í∑∏Î¶ºÎ∞©ÏÜ°</td>\n",
       "      <td>/rinotuna</td>\n",
       "      <td>['ÌïúÍµ≠Ïñ¥']</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§ñ Cat mecha ü§ñ | First mecha commission | Sketc...</td>\n",
       "      <td>/tofusenshi</td>\n",
       "      <td>['czech', 'artcommission']</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Working on covers...| !store !links</td>\n",
       "      <td>/sozomaika</td>\n",
       "      <td>['English']</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ Vtuber ITA ] ~ SUBATHON di Compleanno! Day 7...</td>\n",
       "      <td>/cappuccino_chan</td>\n",
       "      <td>['italiano', 'art', 'illustration']</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>‚ú®üé® your daily dose of motivation üë©‚Äçüé®‚ú®</td>\n",
       "      <td>/vivisartservice</td>\n",
       "      <td>['English', 'art', 'positive']</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>art strimŸ©( ''œâ'' )Ÿà</td>\n",
       "      <td>/ototaaan</td>\n",
       "      <td>['chill', 'Êó•Êú¨Ë™û', 'illustrator']</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>„ÇÑ„Åª</td>\n",
       "      <td>/kingu_ch</td>\n",
       "      <td>['Comfy', 'English', 'Êó•Êú¨Ë™û']</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[18+] Traditional art thursdays! Trying waterc...</td>\n",
       "      <td>/redbeanporridge</td>\n",
       "      <td>['traditionalArt', 'Productivity']</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>frogs are back and trying their best~ // !shop...</td>\n",
       "      <td>/artbyzvesta</td>\n",
       "      <td>['DigitalArt', 'lgbtqia', 'Cosy']</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>re8 dlc recovery room ü©∏ !throw !discord</td>\n",
       "      <td>/cirilla_vt</td>\n",
       "      <td>['Chill', 'Vampire', 'VTuber']</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sculpting Gabriel Angelos / Dawn of War 3 / Da...</td>\n",
       "      <td>/cnotbusch</td>\n",
       "      <td>['Familyfriendly', 'sculpture']</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Only 30 hours more! type !kickstarter to check...</td>\n",
       "      <td>/nisego</td>\n",
       "      <td>['Drawing', 'Nisego', 'English']</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>¬¨ LAST FOUR !streamink ¬¨ !kofi ¬¨ !huel</td>\n",
       "      <td>/sezza</td>\n",
       "      <td>['drawing', 'draw', 'artcommissions']</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3D Vtuber Waifus üíºShirahiko Day 16üíº</td>\n",
       "      <td>/shonzo</td>\n",
       "      <td>['3DModeling', 'English', 'Anime']</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cyno's grippers be looking tasty</td>\n",
       "      <td>/homodacchi</td>\n",
       "      <td>['LGBTQIAplus', 'Asian', 'English']</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DOODLES TO END STREAM</td>\n",
       "      <td>/paperbag_ch</td>\n",
       "      <td>['SplashWomanThePresequel']</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>We're building a Corner Store in 3D! C4D + Oct...</td>\n",
       "      <td>/planetzomax</td>\n",
       "      <td>['octane', 'CGI', 'zomax']</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>„Å°„Çá„Å£„Å®ÁµµÊèè„ÅÑ„Åü„Çä„Åó„Çà„ÅÜ„Åã„Å™</td>\n",
       "      <td>/viva_h</td>\n",
       "      <td>['illustration', 'Êº´Áîª']</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Umbreon I choose you! chat, watch or lurk!</td>\n",
       "      <td>/sariaarts</td>\n",
       "      <td>['English', 'British', 'Cooperative']</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>will i ever finish this</td>\n",
       "      <td>/jasjaws</td>\n",
       "      <td>['English']</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>keep working and no dying pls ‚ú¶ !commissions !...</td>\n",
       "      <td>/lunacyhilly</td>\n",
       "      <td>['ArtCommissions', 'VTuber']</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[Vartist] smol paper dgjashgdhasjhd !commissio...</td>\n",
       "      <td>/papertalisman</td>\n",
       "      <td>['Live2d', 'Drawing', 'English']</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Live2d Rigging ; Games later</td>\n",
       "      <td>/rotuslotus</td>\n",
       "      <td>['Live2D', 'English']</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Squaktober streaaam!!! looking at everyone's b...</td>\n",
       "      <td>/ipaintbirbs</td>\n",
       "      <td>['giddyup', 'dingus', 'chill']</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Designing dnd chars day !</td>\n",
       "      <td>/muchinery</td>\n",
       "      <td>['artcommissions', 'asexual']</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[EN/JP] Chainsaw Man Collab with Sujipii~ (!co...</td>\n",
       "      <td>/darkco4</td>\n",
       "      <td>['design', 'original', 'fanart']</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>‚≠êÔ∏èArt‚≠êÔ∏è |Screaming [Eng/UK | 18+ | They/Them]</td>\n",
       "      <td>/hozzerino</td>\n",
       "      <td>['VTuber', 'UseMeLikeATissue']</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[ENG/‰∏≠Êñá] ‚ú®Community Art Bun Bun ~ Let's embrac...</td>\n",
       "      <td>/starlowvince</td>\n",
       "      <td>['Celebration', 'Chatty', 'Malaysia']</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td> ö(*¬¥Íí≥`*)…û Huevember Day 3 || !garden !study ||...</td>\n",
       "      <td>/chacuri</td>\n",
       "      <td>['procreate', 'huevember', 'English']</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title               url  \\\n",
       "0   BIRTHDAY MARATHON! Begins Oct. 29th at 11:00am...          /bobross   \n",
       "1                                           Î¶¨ÎÖ∏Ï∞∏Ïπò Í∑∏Î¶ºÎ∞©ÏÜ°         /rinotuna   \n",
       "2   ü§ñ Cat mecha ü§ñ | First mecha commission | Sketc...       /tofusenshi   \n",
       "3                 Working on covers...| !store !links        /sozomaika   \n",
       "4   [ Vtuber ITA ] ~ SUBATHON di Compleanno! Day 7...  /cappuccino_chan   \n",
       "5               ‚ú®üé® your daily dose of motivation üë©‚Äçüé®‚ú®  /vivisartservice   \n",
       "6                                art strimŸ©( ''œâ'' )Ÿà         /ototaaan   \n",
       "7                                                  „ÇÑ„Åª         /kingu_ch   \n",
       "8   [18+] Traditional art thursdays! Trying waterc...  /redbeanporridge   \n",
       "9   frogs are back and trying their best~ // !shop...      /artbyzvesta   \n",
       "10            re8 dlc recovery room ü©∏ !throw !discord       /cirilla_vt   \n",
       "11  Sculpting Gabriel Angelos / Dawn of War 3 / Da...        /cnotbusch   \n",
       "12  Only 30 hours more! type !kickstarter to check...           /nisego   \n",
       "13             ¬¨ LAST FOUR !streamink ¬¨ !kofi ¬¨ !huel            /sezza   \n",
       "14                3D Vtuber Waifus üíºShirahiko Day 16üíº           /shonzo   \n",
       "15                   Cyno's grippers be looking tasty       /homodacchi   \n",
       "16                              DOODLES TO END STREAM      /paperbag_ch   \n",
       "17  We're building a Corner Store in 3D! C4D + Oct...      /planetzomax   \n",
       "18                                     „Å°„Çá„Å£„Å®ÁµµÊèè„ÅÑ„Åü„Çä„Åó„Çà„ÅÜ„Åã„Å™           /viva_h   \n",
       "19         Umbreon I choose you! chat, watch or lurk!        /sariaarts   \n",
       "20                            will i ever finish this          /jasjaws   \n",
       "21  keep working and no dying pls ‚ú¶ !commissions !...      /lunacyhilly   \n",
       "22  [Vartist] smol paper dgjashgdhasjhd !commissio...    /papertalisman   \n",
       "23                       Live2d Rigging ; Games later       /rotuslotus   \n",
       "24  Squaktober streaaam!!! looking at everyone's b...      /ipaintbirbs   \n",
       "25                          Designing dnd chars day !        /muchinery   \n",
       "26  [EN/JP] Chainsaw Man Collab with Sujipii~ (!co...          /darkco4   \n",
       "27      ‚≠êÔ∏èArt‚≠êÔ∏è |Screaming [Eng/UK | 18+ | They/Them]        /hozzerino   \n",
       "28  [ENG/‰∏≠Êñá] ‚ú®Community Art Bun Bun ~ Let's embrac...     /starlowvince   \n",
       "29   ö(*¬¥Íí≥`*)…û Huevember Day 3 || !garden !study ||...          /chacuri   \n",
       "\n",
       "                                     tags  viewers  \n",
       "0                             ['English']       16  \n",
       "1                                 ['ÌïúÍµ≠Ïñ¥']      841  \n",
       "2              ['czech', 'artcommission']      229  \n",
       "3                             ['English']      234  \n",
       "4     ['italiano', 'art', 'illustration']       64  \n",
       "5          ['English', 'art', 'positive']       93  \n",
       "6         ['chill', 'Êó•Êú¨Ë™û', 'illustrator']       32  \n",
       "7             ['Comfy', 'English', 'Êó•Êú¨Ë™û']       59  \n",
       "8      ['traditionalArt', 'Productivity']       95  \n",
       "9       ['DigitalArt', 'lgbtqia', 'Cosy']      126  \n",
       "10         ['Chill', 'Vampire', 'VTuber']      138  \n",
       "11        ['Familyfriendly', 'sculpture']      141  \n",
       "12       ['Drawing', 'Nisego', 'English']       95  \n",
       "13  ['drawing', 'draw', 'artcommissions']      102  \n",
       "14     ['3DModeling', 'English', 'Anime']      142  \n",
       "15    ['LGBTQIAplus', 'Asian', 'English']       43  \n",
       "16            ['SplashWomanThePresequel']       34  \n",
       "17             ['octane', 'CGI', 'zomax']       58  \n",
       "18                 ['illustration', 'Êº´Áîª']      170  \n",
       "19  ['English', 'British', 'Cooperative']       30  \n",
       "20                            ['English']       16  \n",
       "21           ['ArtCommissions', 'VTuber']       51  \n",
       "22       ['Live2d', 'Drawing', 'English']       19  \n",
       "23                  ['Live2D', 'English']       47  \n",
       "24         ['giddyup', 'dingus', 'chill']      148  \n",
       "25          ['artcommissions', 'asexual']       78  \n",
       "26       ['design', 'original', 'fanart']       28  \n",
       "27         ['VTuber', 'UseMeLikeATissue']       84  \n",
       "28  ['Celebration', 'Chatty', 'Malaysia']       49  \n",
       "29  ['procreate', 'huevember', 'English']       13  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_selenium = pd.DataFrame(selenium_content)\n",
    "df_selenium = df_selenium.replace(\"\", np.nan).fillna(value=\"NA\")\n",
    "df_selenium.to_csv(\"webscraping_selenium_output.csv\",\n",
    "          index=False,\n",
    "          sep=\";\",\n",
    "          encoding=\"utf-8\")\n",
    "df_read=pd.read_csv(\"webscraping_selenium_output.csv\",sep=';')#.head(5).partner\n",
    "df_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### playwright example: has error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: playwright in d:\\anaconda3\\lib\\site-packages (1.27.1)\n",
      "Requirement already satisfied: pyee==8.1.0 in d:\\anaconda3\\lib\\site-packages (from playwright) (8.1.0)\n",
      "Requirement already satisfied: greenlet==1.1.3 in d:\\anaconda3\\lib\\site-packages (from playwright) (1.1.3)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda3\\lib\\site-packages (from playwright) (4.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Node.js is only supported on Windows 8.1, Windows Server 2012 R2, or higher.\n",
      "Setting the NODE_SKIP_PLATFORM_CHECK environment variable to 1 skips this\n",
      "check, but Node.js might not execute correctly. Any issues encountered on\n",
      "unsupported platforms will not be fixed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython in d:\\anaconda3\\lib\\site-packages (7.8.0)\n",
      "Requirement already satisfied: nest_asyncio in d:\\anaconda3\\lib\\site-packages (1.5.6)\n",
      "Requirement already satisfied: traitlets>=4.2 in d:\\anaconda3\\lib\\site-packages (from ipython) (4.3.3)\n",
      "Requirement already satisfied: jedi>=0.10 in d:\\anaconda3\\lib\\site-packages (from ipython) (0.15.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in d:\\anaconda3\\lib\\site-packages (from ipython) (41.4.0)\n",
      "Requirement already satisfied: decorator in d:\\anaconda3\\lib\\site-packages (from ipython) (4.4.0)\n",
      "Requirement already satisfied: backcall in d:\\anaconda3\\lib\\site-packages (from ipython) (0.1.0)\n",
      "Requirement already satisfied: pygments in d:\\anaconda3\\lib\\site-packages (from ipython) (2.4.2)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from ipython) (0.4.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from ipython) (2.0.10)\n",
      "Requirement already satisfied: pickleshare in d:\\anaconda3\\lib\\site-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: parso>=0.5.0 in d:\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython) (0.5.1)\n",
      "Requirement already satisfied: wcwidth in d:\\anaconda3\\lib\\site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (0.1.7)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\anaconda3\\lib\\site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (1.12.0)\n",
      "Requirement already satisfied: ipython-genutils in d:\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install playwright\n",
    "!playwright install\n",
    "!{sys.executable} -m pip install ipython nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\python.exe: No module named from\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sync_playwright' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-17697539c3a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{sys.executable} -m from playwright.sync_api import sync_playwright'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0msync_playwright\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mbrowser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchromium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheadless\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mviewport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"width\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1920\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"height\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1080\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sync_playwright' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "## error : module 'attr' has no attribute 'frozen'\n",
    "\n",
    "!{sys.executable} -m from playwright.sync_api import sync_playwright\n",
    "\n",
    "with sync_playwright() as pw:\n",
    "    browser = pw.chromium.launch(headless=False)\n",
    "    context = browser.new_context(viewport={\"width\": 1920, \"height\": 1080})\n",
    "    page = context.new_page()\n",
    "\n",
    "    page.goto(\"https://twitch.tv/directory/game/Art\")  # go to url\n",
    "    page.wait_for_selector(\"div[data-target=directory-first-item]\")  # wait for content to load\n",
    "    print(page.content())\n",
    "    selenium_content=page.content()\n",
    "    \n",
    "parsed = []\n",
    "for item in soup.select(\".tw-tower div[data-target]\"):\n",
    "    parsed.append({\n",
    "        'title': item.select_one('h3').text,\n",
    "        'url': item.select_one('.tw-link::attr(href)').attrs.get(\"href\"),\n",
    "        #'username': item.select_one('.tw-link').text,\n",
    "        'tags': [tag.text for tag in item.select('.tw-tag')],\n",
    "        'viewers': item.select_one('.tw-media-card-stat').text,\n",
    "    })\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
